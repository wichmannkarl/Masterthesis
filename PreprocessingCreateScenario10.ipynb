{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "538c9c7a",
   "metadata": {},
   "source": [
    "# Masterthesis\n",
    "## PrecessingCreateSpezialFile\n",
    "\n",
    "On arrangement with the BSI a Scenario (10) file should be used to detect all movements on position of one person.\n",
    "This File creates therefore the new dataset (ID: 71,72,73) as basis for the Screnario10. \n",
    "The Files listed in \"FileScenarioPreconvert.csv\" merge the CSI-Rah files to the new datafiles.\n",
    "\n",
    "**Dataset Files**\n",
    "\n",
    "\n",
    "* Dataset (31,34,35,36,37) -> CSI-Rahfile \"Person-5 - #154 Alle Bewegungen einer Person bei #1\" (ID=71)\n",
    "* Dataset (32,38,39,40,41) -> CSI-Rahfile \"Person-5 - #154 Alle Bewegungen einer Person bei #2\" (ID=72)\n",
    "* Dataset (33,42,43,44,45) -> CSI-Rahfile \"Person-5 - #154 Alle Bewegungen einer Person bei #3\" (ID=73)\n",
    "\n",
    "\n",
    "**Imports and Definitions**\n",
    "- The necessary libraries are loaded here and important variables are defined\n",
    "\n",
    "- Create scenario10 file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48449f57",
   "metadata": {},
   "source": [
    "## Imports and Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091754c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import sklearn\n",
    "import sklearn\n",
    "\n",
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Import numpy\n",
    "import numpy as np\n",
    "\n",
    "# To calculate amplitude and phase\n",
    "import math\n",
    "\n",
    "# Measure runtime of a jupyter jotebook code cell\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "# Used to check if file exists\n",
    "import os\n",
    "\n",
    "# Used to check if directory exists\n",
    "import pathlib\n",
    "\n",
    "# Import Operation System Calls\n",
    "import SubOperationSystem\n",
    "\n",
    "# check os\n",
    "if os.name == 'nt':\n",
    "    print(\"OS is Windows\")\n",
    "    Delimiter = '\\\\'\n",
    "    \n",
    "else:\n",
    "    print(\"OS is Linux\")\n",
    "    Delimiter = '/'\n",
    "    \n",
    "# Path of datasets (root directory)\n",
    "PathDataset = 'Dataset' + Delimiter    \n",
    "\n",
    "# Path of datasets\n",
    "PathDatasetSub = PathDataset + 'CsiFilesRah' + Delimiter\n",
    "        \n",
    "# Path of the converted files\n",
    "PathConverted = PathDataset + 'Converted' + Delimiter\n",
    "\n",
    "# Set path for scenario files\n",
    "PathScenario = PathDataset + 'Scenario' + Delimiter\n",
    "\n",
    "# Set path for scenario files\n",
    "PathResult = PathDataset + 'Result' + Delimiter\n",
    "\n",
    "# Set path for scenario files\n",
    "PathPlot = PathDataset + 'Plot' + Delimiter\n",
    "\n",
    "# Set path for scenario files\n",
    "PathConfig = 'FilesConfig' + Delimiter\n",
    "\n",
    "# Scenariofile (file with info about the ten scenarios)\n",
    "FileScenario = 'FileScenario.csv'\n",
    "\n",
    "# Mappingfile (file with info about original and converted filenames)\n",
    "FileMapping = 'FileMapping.csv'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc368b4",
   "metadata": {},
   "source": [
    "# Create scenario10 file\n",
    "\n",
    "- Read config files FileScenarioPre and FileMapping and merge in a loop the listed files to new CSI-Rahfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7363fb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open scenario mapping file to read\n",
    "dfScenarioPre = pd.read_csv(PathConfig + FileScenarioPre, index_col=0)\n",
    "\n",
    "# Read config File\n",
    "dfFiles = pd.read_csv(PathConfig + FileMapping, index_col=0)\n",
    "\n",
    "# loop through scenario dataframe\n",
    "for ind in dfScenarioPre.index:\n",
    "    \n",
    "    # Get datafile and dataset from dataframe\n",
    "    Filename,Datasets = (dfScenarioPre['Filename'][ind], dfScenarioPre['Datasets'][ind])\n",
    "    \n",
    "    # Create datafile with datasets to write\n",
    "    DatafileSummary = open(PathDataset + PathDatasetSub + Filename + \".csv\", 'w')\n",
    "    \n",
    "    # Split to dataset items because we need a int value\n",
    "    DatasetItems=list(Datasets.split())\n",
    "    \n",
    "     # loop through list DatasetItems\n",
    "    for DatasetItem in DatasetItems:\n",
    "        \n",
    "        # The filenames of needed dataset in the column 'FilenameNew'\n",
    "        DatasetFilenames = dfFiles.loc[int(DatasetItem)]['FilenameOld']\n",
    "\n",
    "        # Read dataset file\n",
    "        FileTemp = pd.read_csv(PathDataset + PathDatasetSub + DatasetFilenames, index_col=0)\n",
    "\n",
    "        # Append DataFrame to file\n",
    "        if DatafileSummary.tell() == 0:\n",
    "\n",
    "            # if file is empty write header\n",
    "            FileTemp.to_csv(DatafileSummary, index=False, line_terminator='\\n')\n",
    "        else:\n",
    "            FileTemp.to_csv(DatafileSummary, index=False, line_terminator='\\n', header=False)\n",
    "    \n",
    "    # close file\n",
    "    DatafileSummary.close\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
