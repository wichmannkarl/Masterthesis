{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9dcbe60f",
   "metadata": {},
   "source": [
    "# Masterthesis\n",
    "## Create Plots for Machine Learning results\n",
    "\n",
    "This script create box plots to visualize the machine learning results.\n",
    "\n",
    "**Imports and Definitions**\n",
    "- The necessary libraries are loaded here and important variables are defined\n",
    "\n",
    "**Imports and settings for this script**\n",
    "- Import libraries and set variables for this script\n",
    "\n",
    "**Create plots of machine learning results**\n",
    "- Result files are loaded to create box plots \n",
    "\n",
    "**Create confusion matrix**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690037c9",
   "metadata": {},
   "source": [
    "## Imports and Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4416196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import sklearn\n",
    "import sklearn\n",
    "\n",
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Import numpy\n",
    "import numpy as np\n",
    "\n",
    "# To calculate amplitude and phase\n",
    "import math\n",
    "\n",
    "# Measure runtime of a jupyter jotebook code cell\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "# Used to check if file exists\n",
    "import os\n",
    "\n",
    "# Used to check if directory exists\n",
    "import pathlib\n",
    "\n",
    "# Import Operation System Calls\n",
    "import SubOperationSystem\n",
    "\n",
    "# check os\n",
    "if os.name == 'nt':\n",
    "    print(\"OS is Windows\")\n",
    "    Delimiter = '\\\\'\n",
    "    \n",
    "else:\n",
    "    print(\"OS is Linux\")\n",
    "    Delimiter = '/'\n",
    "    \n",
    "# Path of datasets (root directory)\n",
    "PathDataset = 'Dataset' + Delimiter    \n",
    "\n",
    "# Path of datasets\n",
    "PathDatasetSub = PathDataset + 'CsiFilesRah' + Delimiter\n",
    "        \n",
    "# Path of the converted files\n",
    "PathConverted = PathDataset + 'Converted' + Delimiter\n",
    "\n",
    "# Set path for scenario files\n",
    "PathScenario = PathDataset + 'Scenario' + Delimiter\n",
    "\n",
    "# Set path for scenario files\n",
    "PathResult = PathDataset + 'Result' + Delimiter\n",
    "\n",
    "# Set path for scenario files\n",
    "PathPlot = PathDataset + 'Plot' + Delimiter\n",
    "\n",
    "# Set path for scenario files\n",
    "PathConfig = 'FilesConfig' + Delimiter\n",
    "\n",
    "# Scenariofile (file with info about the ten scenarios)\n",
    "FileScenario = 'FileScenario.csv'\n",
    "\n",
    "# Mappingfile (file with info about original and converted filenames)\n",
    "FileMapping = 'FileMapping.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe5ce8c",
   "metadata": {},
   "source": [
    "# Imports and settings for this script\n",
    "\n",
    "Bevor running set the parameter \"PCA\" to True / False\n",
    "\n",
    "With \"PCA=True\" the plot with the pca results will be created, else without PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6eaa1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import warings and set warn level to ignore\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "####################################################################################\n",
    "\n",
    "# Select if the plots with or without PCA should be create\n",
    "# Set PCA to True or False\n",
    "\n",
    "Pca = False\n",
    "# Pca = True\n",
    "\n",
    "####################################################################################\n",
    "\n",
    "# Set file for algorithm\n",
    "FileAlgorithm = 'FileAlgorithm.csv'\n",
    "\n",
    "# Set path where the result files saved\n",
    "if not Pca:\n",
    "    print('Result without PCA')\n",
    "    PathResult = PathResult + 'ResultWithoutPca' + Delimiter\n",
    "       \n",
    "else:\n",
    "    print('Result with PCA')\n",
    "    PathResult = PathResult + 'ResultWithPca' + Delimiter\n",
    "    \n",
    "\n",
    "# Suffic for plot\n",
    "Label = '' if not Pca else '_pca'   \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f218eaf",
   "metadata": {},
   "source": [
    "## Create plots of machine learning results\n",
    "\n",
    "This script read the result files and create the plots to save it as png file.\n",
    "\n",
    "Following files are needed\n",
    "\n",
    "* Scenario file - this file contrains the scenarios\n",
    "* Mapping file - with mapping between the number and the name of the dataset\n",
    "* Algorithm file - as a list of the used algrithm\n",
    "* (*).acc file - with the ML results\n",
    "* The results are saved in 'PathPlot'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d92c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open scenario mapping file to read\n",
    "dfScenario = pd.read_csv(PathConfig + FileScenario)\n",
    "\n",
    "# Loop through scenario dataframe to get movements\n",
    "for ind in dfScenario.index:\n",
    "\n",
    "    # Create empty lists\n",
    "    DataToPlot = []\n",
    "    ScenarienCounter = []\n",
    "    listAlgorithmDisplayName = []\n",
    "    listMovementDisplayName = []\n",
    "    \n",
    "    # Get scenarios and dataset from dataframe\n",
    "    Scenario,Datasets = (dfScenario['Scenario'][ind], dfScenario['Datasets'][ind])\n",
    "    \n",
    "    # Get values of movements\n",
    "    DatasetItems=list(Datasets.split())\n",
    "\n",
    "    # Read Filemapping file. This file contains the name for movements\n",
    "    dfFileMapping = pd.read_csv(PathConfig + FileMapping ,names=['LineNumber','FilenameOld','FilenameNew'], skiprows=1)\n",
    "        \n",
    "    # Loop through DatasetItems\n",
    "    for DatasetItem in DatasetItems:\n",
    "            \n",
    "        # Loop through mapping dataframe to get number of movments\n",
    "        for ind in dfFileMapping.index:\n",
    "    \n",
    "            # Get scenarios and dataset from dataframe\n",
    "            LineNumber,FilenameNew = (dfFileMapping['LineNumber'][ind], dfFileMapping['FilenameNew'][ind])\n",
    "            \n",
    "            # Test if Scenario equal ScenarioName\n",
    "            if int(DatasetItem) == LineNumber:\n",
    "                \n",
    "                # Then replace\n",
    "                FilenameNew = FilenameNew.replace(\".csv\",\"\")\n",
    "                FilenameNew = FilenameNew.replace(\"_\",\" \")\n",
    "                                \n",
    "                # And append to list\n",
    "                listMovementDisplayName.append(FilenameNew)\n",
    "    \n",
    "    # Read algorithm file to get count of used algorithm an name of algorithm\n",
    "    dfAlgorithm = pd.read_csv(PathConfig + FileAlgorithm,names=['LineNumber','Algorithm','DisplayNameAlgorithm'], skiprows=1)\n",
    "    \n",
    "    # Get algorithmn display name\n",
    "    listAlgorithmDisplayName = dfAlgorithm['DisplayNameAlgorithm'].tolist()\n",
    "    \n",
    "    # Loop through algorithm\n",
    "    for Algorithm in dfAlgorithm.index:\n",
    "    \n",
    "        # Read the txt file which is formatted as a csv into a dataframe and name\n",
    "        dfResults = pd.read_csv(PathResult + Scenario + \"_\" + dfAlgorithm['Algorithm'][Algorithm] + \".csv\")\n",
    "        \n",
    "        # Set name for algorithm\n",
    "        dfResults.rename(columns={dfResults.columns[0]: \"algorithm\"}, inplace = True)\n",
    "        \n",
    "        # Drop unwanted columns\n",
    "        dfResults = dfResults.drop('precision', axis=1)\n",
    "        dfResults = dfResults.drop('recall', axis=1)\n",
    "        dfResults = dfResults.drop('support', axis=1)\n",
    "        \n",
    "        # Drop unwanted rows\n",
    "        dfResults = dfResults.drop(dfResults[dfResults['algorithm'] == 'accuracy'].index)\n",
    "        dfResults = dfResults.drop(dfResults[dfResults['algorithm'] == 'macro avg'].index)\n",
    "        dfResults = dfResults.drop(dfResults[dfResults['algorithm'] == 'weighted avg'].index)\n",
    "    \n",
    "        # Create a empty list\n",
    "        listScenario = []    \n",
    "            \n",
    "        # Loop through DatasetItems\n",
    "        for DatasetItem in DatasetItems:\n",
    "\n",
    "            # Loop through result file\n",
    "            for ind in dfResults.index:\n",
    "                \n",
    "                # Read algorithm and f1-score\n",
    "                dfResultAlgorithm, dfResultF1Score = (dfResults['algorithm'][ind], dfResults['f1-score'][ind])\n",
    "\n",
    "                # Compare DatasetItem and dfResultAlgorithm\n",
    "                if int(DatasetItem) == int(dfResultAlgorithm):\n",
    "                    \n",
    "                    # Add dfResultF1Score to list\n",
    "                    listScenario.append(dfResultF1Score)\n",
    "        \n",
    "        # Add to Scenario list\n",
    "        DataToPlot.append(listScenario)\n",
    "    \n",
    "    # Transpose the list\n",
    "    DataToPlot = list(map(list, zip(*DataToPlot)))\n",
    "    \n",
    "    # Count groups (= Algorithm)\n",
    "    CounterAlgorithm = np.arange(len(dfAlgorithm))\n",
    "    \n",
    "    # Create plot\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    # Set height of y-axis\n",
    "    plt.ylim(0, 10)\n",
    "    \n",
    "    # Add subplots\n",
    "    ax = fig.add_axes([0,0,1,1])\n",
    "  \n",
    "    # Create bar depend on the List of the List\n",
    "    for bar in range(len(DataToPlot)):\n",
    "\n",
    "        # We need other settings if plots are more then 14 bars\n",
    "        if len(DataToPlot) < 15:\n",
    "            widthBar = 0.1\n",
    "            spaceBar = 10\n",
    "        else:\n",
    "            widthBar = 0.05\n",
    "            spaceBar = 20\n",
    "            \n",
    "        # Create bars\n",
    "        ax.bar(CounterAlgorithm + (bar/spaceBar), DataToPlot[bar], width = widthBar)\n",
    "     \n",
    "    # Count listAlgorithmDisplayName\n",
    "    arangeLADN = np.arange(len(listAlgorithmDisplayName))\n",
    "    \n",
    "    # Get the number of items\n",
    "    countLADN = len(DataToPlot)\n",
    "    \n",
    "    # Settings for plots\n",
    "    if countLADN == 3:\n",
    "        xticksWidth = 0.1\n",
    "    elif countLADN == 5:\n",
    "        xticksWidth = 0.2\n",
    "    else:\n",
    "        xticksWidth = 0.35\n",
    "    \n",
    "    # Settings for xticks\n",
    "    ax.set_xticks(arangeLADN + xticksWidth, listAlgorithmDisplayName, rotation=90) \n",
    "    \n",
    "    # Set legend\n",
    "    ax.legend(listMovementDisplayName, bbox_to_anchor=(1.05, 1), loc='upper left' )\n",
    "    \n",
    "    # Set scenario name (with oder without PCA)\n",
    "    PlotScenarioName = Scenario if not Pca else Scenario + ' - With PCA'\n",
    "    \n",
    "    # Set scenario name for title\n",
    "    PlotScenarioName = PlotScenarioName.replace(\"Scenario\",\"Szenario\")\n",
    "    PlotScenarioName = PlotScenarioName.replace(\"10\",\"xx\")\n",
    "    PlotScenarioName = PlotScenarioName.replace(\"0\",\" \")\n",
    "    PlotScenarioName = PlotScenarioName.replace(\"xx\",\" 10\")\n",
    "        \n",
    "    # Set title, x and y label\n",
    "    ax.set(title=PlotScenarioName, ylabel='F1-Score in %', xlabel='Algorithmen')\n",
    "    \n",
    "    # Create plot\n",
    "    plt.savefig(PathPlot + Scenario + Label, dpi=300, bbox_inches = 'tight')\n",
    "    \n",
    "    # Show plot\n",
    "    plt.show();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88ada34",
   "metadata": {},
   "source": [
    "# Create Plot for SHAP Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7809469b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Data to plot\n",
    "X = np.array([\"6\",\"58\",\"7\",\"43\",\"44\",\"45\",\"34\",\"49\",\"46\",\"33\",\"38\",\"39\",\"13\",\"53\"])\n",
    "y = np.array([11,10,5,4,4,4,3,3,3,3,3,3,3,3])\n",
    "\n",
    "# Create plots\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(X,y)\n",
    "plt.xlabel('Bezeichung der Subträger')\n",
    "plt.ylabel('Anzahl der Subträger')\n",
    "plt.title('Übersicht der Subträger mit den höchsten Score')\n",
    "plt.savefig(PathPlot + 'SummaryPlotSubcarrierShap.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbc9c78",
   "metadata": {},
   "source": [
    "# Create confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639c5b41",
   "metadata": {},
   "source": [
    "# Imports and Settings for this script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4663ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import for confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Import mathplotlib for plots\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import searborn\n",
    "import seaborn as sns\n",
    "\n",
    "# Set algorithm file\n",
    "FileAlgorithm = 'FileAlgorithm.csv'\n",
    "\n",
    "# Extension for this plots\n",
    "FileExtension = '_cm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b199881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open scenario mapping file to read\n",
    "dfScenario = pd.read_csv(PathConfig + FileScenario)\n",
    "\n",
    "# Read file mapping\n",
    "dfFiles = pd.read_csv(PathConfig + FileMapping)\n",
    "\n",
    "# Read algorithm file to get count of used algorithm an name of algorithm\n",
    "dfAlgorithm = pd.read_csv(PathConfig + FileAlgorithm)\n",
    "   \n",
    "# Loop through scenario dataframe to get movements\n",
    "for indexScenario in dfScenario.index:\n",
    "\n",
    "    # Get scenarios and dataset from dataframe\n",
    "    Scenario,Datasets = (dfScenario['Scenario'][indexScenario],dfScenario['Datasets'][indexScenario])\n",
    "   \n",
    "    # List for column and row names\n",
    "    listColumns = []\n",
    "        \n",
    "    # split to dataset items because we need a int value\n",
    "    DatasetItems=list(Datasets.split())\n",
    "    \n",
    "    # loop through list\n",
    "    for DatasetItem in DatasetItems:\n",
    "\n",
    "        # filenames of needed dataset in the column 'FilenameNew' (-1 because the index beginn at 0)\n",
    "        DatasetFilenames = dfFiles.loc[int(DatasetItem)-1]['FilenameNew']\n",
    "            \n",
    "        # Clean up\n",
    "        DatasetFilenames = DatasetFilenames.replace(\".csv\",\"\")\n",
    "        DatasetFilenames = DatasetFilenames.replace(\"_\",\" \")\n",
    "        \n",
    "        # listMovementDisplayName.append(FilenameNew)\n",
    "        listColumns.append(DatasetFilenames) \n",
    "    \n",
    "    # Loop through algorithm\n",
    "    for indexAlgorithmus in dfAlgorithm.index:\n",
    "\n",
    "        # Get name of algorithm\n",
    "        Algorithm = (dfAlgorithm['Algorithm'][indexAlgorithmus])\n",
    "        \n",
    "        # Open scenario mapping file to read\n",
    "        dfCm = pd.read_csv(PathResult + Scenario + '_' + Algorithm + '.cm', index_col=0)\n",
    "\n",
    "        # Fehler\n",
    "        dfCm = dfCm.set_axis(listColumns, axis=1)\n",
    "\n",
    "        # Fehler\n",
    "        dfCm = dfCm.set_axis(listColumns, axis=0)\n",
    "        \n",
    "        # Transpose data\n",
    "        mcmc = pd.DataFrame(dfCm).transpose()\n",
    "\n",
    "        # Count of columns\n",
    "        countColumns = dfCm.shape[1]\n",
    "        \n",
    "        # Set size of matrix\n",
    "        plt.figure(figsize=(countColumns, countColumns))\n",
    "        \n",
    "        # Data to plot\n",
    "        cm_df = pd.DataFrame(dfCm, index = listColumns, columns = listColumns)\n",
    "              \n",
    "        # Plot confusion matrix, cmap = color, fmt = format of values\n",
    "        sns.heatmap(cm_df, annot = True, cmap = \"YlGnBu\", fmt =' .2f')\n",
    "        \n",
    "        # Set title name\n",
    "        plt.title('Konfusionsmatrix - ' + Scenario + ' - ' + Algorithm, y=1.1)\n",
    "\n",
    "        # Set ylabel\n",
    "        plt.ylabel('Prognostizierte Klasse')\n",
    "        \n",
    "        # Set xlabel\n",
    "        plt.xlabel('Tatsächliche Klasse')\n",
    "        \n",
    "        # Rotate xticks\n",
    "        plt.xticks(rotation=90)\n",
    "        \n",
    "        # Rotate yticks\n",
    "        plt.yticks(rotation=0)\n",
    "        \n",
    "        # Set tight layout\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save plot\n",
    "        plt.savefig(PathPlot + Scenario + '_' + Algorithm + FileExtension + '.png', bbox_inches = \"tight\")\n",
    "\n",
    "        # Show plot\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fb4efc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
