{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "538c9c7a",
   "metadata": {},
   "source": [
    "# Masterthesis\n",
    "## Reporting: explained Varianz\n",
    "\n",
    "This script calculate the explained varianz for all scenarios.\n",
    "\n",
    "- Imports and Definitions\n",
    "\n",
    "- Imports for this script\n",
    "\n",
    "- Function for variance\n",
    "\n",
    "- Calculate variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48449f57",
   "metadata": {},
   "source": [
    "## Imports and Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091754c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import sklearn\n",
    "import sklearn\n",
    "\n",
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Import numpy\n",
    "import numpy as np\n",
    "\n",
    "# To calculate amplitude and phase\n",
    "import math\n",
    "\n",
    "# Measure runtime of a jupyter jotebook code cell\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "# Used to check if file exists\n",
    "import os\n",
    "\n",
    "# Used to check if directory exists\n",
    "import pathlib\n",
    "\n",
    "# Import Operation System Calls\n",
    "import SubOperationSystem\n",
    "\n",
    "# check os\n",
    "if os.name == 'nt':\n",
    "    print(\"OS is Windows\")\n",
    "    Delimiter = '\\\\'\n",
    "    \n",
    "else:\n",
    "    print(\"OS is Linux\")\n",
    "    Delimiter = '/'\n",
    "    \n",
    "# Path of datasets (root directory)\n",
    "PathDataset = 'Dataset' + Delimiter    \n",
    "\n",
    "# Path of datasets\n",
    "PathDatasetSub = PathDataset + 'CsiFilesRah' + Delimiter\n",
    "        \n",
    "# Path of the converted files\n",
    "PathConverted = PathDataset + 'Converted' + Delimiter\n",
    "\n",
    "# Set path for scenario files\n",
    "PathScenario = PathDataset + 'Scenario' + Delimiter\n",
    "\n",
    "# Set path for scenario files\n",
    "PathResult = PathDataset + 'Result' + Delimiter\n",
    "\n",
    "# Set path for scenario files\n",
    "PathPlot = PathDataset + 'Plot' + Delimiter\n",
    "\n",
    "# Set path for scenario files\n",
    "PathConfig = 'FilesConfig' + Delimiter\n",
    "\n",
    "# Scenariofile (file with info about the ten scenarios)\n",
    "FileScenario = 'FileScenario.csv'\n",
    "\n",
    "# Mappingfile (file with info about original and converted filenames)\n",
    "FileMapping = 'FileMapping.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585c1093",
   "metadata": {},
   "source": [
    "# Imports for this script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3819d354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Import PCA\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Result Files\n",
    "FileResultFilterHampel = \"FileResultFilterHampel.csv\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82179807",
   "metadata": {},
   "source": [
    "# Function for variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46d3a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Def function Varianzce\n",
    "# X are the samples without label\n",
    "# n is the count of components\n",
    "def Variance(X, n):\n",
    "    \n",
    "    # Create instance for scaler\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    # Create instance for pca\n",
    "    pca = PCA(n_components = n)\n",
    "    \n",
    "    # Fit and fit_transform X\n",
    "    pca.fit(scaler.fit_transform(X))\n",
    "\n",
    "    # return of explained variance (Sum)\n",
    "    return pca.explained_variance_ratio_.cumsum()[-1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8535184",
   "metadata": {},
   "source": [
    "# Calculate variance\n",
    "- Read config scenario file for names of scenarios\n",
    "- Call function varianz to calcuate cumulated varianz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05dc1045",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# open scenario mapping file to read\n",
    "dfScenario = pd.read_csv(PathConfig + FileScenario, index_col=0)\n",
    "\n",
    "# loop through scenario dataframe\n",
    "for ind in dfScenario.index:\n",
    "    \n",
    "    # get scenarios and dataset from dataframe\n",
    "    Scenario = (dfScenario['Scenario'][ind])\n",
    "    \n",
    "    # read scenario files\n",
    "    df = pd.read_csv(PathScenario + Scenario + \"_ah.csv\")\n",
    "\n",
    "    # drop label column\n",
    "    X = df.drop(columns=['label']).values\n",
    "\n",
    "    # Print scenario name\n",
    "    print(Scenario)\n",
    "    print(80 * '=')\n",
    "        \n",
    "    # Loop through count of features\n",
    "    for f in range(1,53):\n",
    "        \n",
    "        # Print result\n",
    "        print('Components:\\t', f, '=\\t', Variance(X, f), '\\tCumulative Variance')\n",
    "    \n",
    "    # Print line\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
