{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91cc5c3d",
   "metadata": {},
   "source": [
    "# Masterthesis\n",
    "## Machine learning\n",
    "\n",
    "This script executes the machine learning algorithms either with or without pca with the specified hyperparameters across following algorithms:\n",
    "\n",
    "- RandomForest\n",
    "\n",
    "- LogisticRegession\n",
    "\n",
    "- KNeighborsClassifier\n",
    "\n",
    "- SVM\n",
    "\n",
    "- GradientBoostingClassifier\n",
    "\n",
    "**Imports and Definitions**\n",
    "- The necessary libraries are loaded here and important variables are defined\n",
    "\n",
    "**Imports and settings for this script**\n",
    "- Import libraries and set variables for this script\n",
    "\n",
    "**Preparation for Machine Learning**\n",
    "- Set path and values\n",
    "\n",
    "**Machine Learning**\n",
    "- Run the machine learning algorithmen either with or without pca\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830a2b82",
   "metadata": {},
   "source": [
    "## Imports and Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20e652d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OS is Windows\n"
     ]
    }
   ],
   "source": [
    "# Import sklearn\n",
    "import sklearn\n",
    "\n",
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Import numpy\n",
    "import numpy as np\n",
    "\n",
    "# To calculate amplitude and phase\n",
    "import math\n",
    "\n",
    "# Measure runtime of a jupyter jotebook code cell\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "# Used to check if file exists\n",
    "import os\n",
    "\n",
    "# Used to check if directory exists\n",
    "import pathlib\n",
    "\n",
    "# Import Operation System Calls\n",
    "import SubOperationSystem\n",
    "\n",
    "# check os\n",
    "if os.name == 'nt':\n",
    "    print(\"OS is Windows\")\n",
    "    Delimiter = '\\\\'\n",
    "    \n",
    "else:\n",
    "    print(\"OS is Linux\")\n",
    "    Delimiter = '/'\n",
    "    \n",
    "# Path of datasets (root directory)\n",
    "PathDataset = 'Dataset' + Delimiter    \n",
    "\n",
    "# Path of datasets\n",
    "PathDatasetSub = PathDataset + 'CsiFilesRah' + Delimiter\n",
    "        \n",
    "# Path of the converted files\n",
    "PathConverted = PathDataset + 'Converted' + Delimiter\n",
    "\n",
    "# Set path for scenario files\n",
    "PathScenario = PathDataset + 'Scenario' + Delimiter\n",
    "\n",
    "# Set path for scenario files\n",
    "PathResult = PathDataset + 'Result' + Delimiter\n",
    "\n",
    "# Set path for scenario files\n",
    "PathPlot = PathDataset + 'Plot' + Delimiter\n",
    "\n",
    "# Set path for scenario files\n",
    "PathConfig = 'FilesConfig' + Delimiter\n",
    "\n",
    "# Scenariofile (file with info about the ten scenarios)\n",
    "FileScenario = 'FileScenario.csv'\n",
    "\n",
    "# Mappingfile (file with info about original and converted filenames)\n",
    "FileMapping = 'FileMapping.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e22dbc-eac2-4832-9a74-bfffba5c214f",
   "metadata": {},
   "source": [
    "# Imports and settings for this script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b871d23-7621-4830-998f-8c47ff642935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Train-Test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import Classifier RF and GBC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "# Import Classifier SVC\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Import Classifier LG\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Import Classifier KNC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Import StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Import PCA\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Import Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# import metrics and roc_auc_score\n",
    "from sklearn import metrics\n",
    "\n",
    "# Import Metrics - accuracy score, confusion matrix, classification report and confusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "\n",
    "# Import seaborn\n",
    "import seaborn as sns\n",
    "\n",
    "# used for separate windows for graphics\n",
    "%matplotlib inline\n",
    "\n",
    "# import pickle to save learned model\n",
    "import pickle\n",
    "\n",
    "# Install interpet\n",
    "from interpret import set_visualize_provider\n",
    "\n",
    "# Install interpret.provider\n",
    "from interpret.provider import InlineProvider\n",
    "\n",
    "# Import ExplainableBoostingClassifier\n",
    "from interpret.glassbox import ExplainableBoostingClassifier\n",
    "\n",
    "# Import show\n",
    "from interpret import show\n",
    "\n",
    "# Import roc_auc_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Import average_precision_score, precision_recall_curve, auc\n",
    "from sklearn.metrics import average_precision_score, precision_recall_curve, auc\n",
    "\n",
    "# import mathplot\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8130f522",
   "metadata": {},
   "source": [
    "# Preparation for Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a16a3df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set PCA to True or False\n",
    "PCA = True\n",
    "# PCA = False\n",
    "\n",
    "# Set value for PCA\n",
    "n_components = 30\n",
    "\n",
    "# Counter for Hyperparameter\n",
    "CounterHp = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1d3f75-cd87-48ff-b13a-3be95eabac8c",
   "metadata": {},
   "source": [
    "# Machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ced18e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Pca setting\n",
    "if PCA:\n",
    "    # Label\n",
    "    Label = 'PCA'\n",
    "    \n",
    "    # Set file extension\n",
    "    FileExtension = '_pca'\n",
    "    \n",
    "    # Hyperparameter file\n",
    "    FileHyperparameter = 'FileHyperparameterWithPca.csv'\n",
    "\n",
    "else:\n",
    "    # Label\n",
    "    Label = ''\n",
    "\n",
    "    # Set file extension\n",
    "    FileExtension = '_pca'\n",
    "\n",
    "    # Hyperparameter file\n",
    "    FileHyperparameter = 'FileHyperparameterWithoutPca.csv'\n",
    "    \n",
    "\n",
    "# Read scenario mapping file\n",
    "dfScenario = pd.read_csv(PathConfig + FileScenario, sep=',')\n",
    "\n",
    "# Read Hyperparameter file\n",
    "dfHp = pd.read_csv(PathConfig + FileHyperparameter, sep=',')\n",
    "\n",
    "# Loop through scenario file\n",
    "for ind in dfScenario.index:\n",
    "    \n",
    "    # Get filename of scenario\n",
    "    Scenario = (dfScenario['Scenario'][ind])\n",
    "    \n",
    "    # Search parameter in \n",
    "    for idx in dfHp.index:\n",
    "        HpScenario = (dfHp['Scenario'][idx])\n",
    "        if Scenario == HpScenario:\n",
    "            CounterHp = idx\n",
    "            break\n",
    "\n",
    "    print(80 * '=')\n",
    "    print('Summary')\n",
    "    print(Scenario)\n",
    "    print(dfHp.iloc[CounterHp])\n",
    "    print(80 * '=')\n",
    "\n",
    "    # load scenario file\n",
    "    df = pd.read_csv(PathDataset + PathScenario + Scenario + '_ah.csv')\n",
    "\n",
    "    # Select data and remove target\n",
    "    X = df.drop(\"label\",axis=1)\n",
    "\n",
    "    # Select target\n",
    "    y = df['label']\n",
    "\n",
    "    # Split dataset to train and test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=10)\n",
    "\n",
    "    # Set parameter for confusion matriy (size of figure and font size)\n",
    "    plt.rcParams['figure.figsize'] = (8, 6)\n",
    "    plt.rcParams['font.size'] = 12\n",
    "\n",
    "    # Define machine learing models with determined hyperparameters\n",
    "    models = [\n",
    "        ('RandomForest', RandomForestClassifier(), {\n",
    "            'model__max_depth': [dfHp.RF__max_depth[CounterHp]],\n",
    "            'model__min_samples_leaf': [dfHp.RF__min_samples_leaf[CounterHp]],\n",
    "            'model__min_samples_split': [dfHp.RF__min_samples_split[CounterHp]],\n",
    "            'model__n_estimators': [dfHp.RF__n_estimators[CounterHp]]\n",
    "        }),\n",
    "         \n",
    "        ('LogisticRegession', LogisticRegression(), {\n",
    "            'model__C': [dfHp.LR__C[CounterHp]],\n",
    "            'model__max_iter': [dfHp.LR__max_iter[CounterHp]],\n",
    "            'model__penalty': [dfHp.LR__penalty[CounterHp]],\n",
    "            'model__solver': [dfHp.LR__solver[CounterHp]]\n",
    "        }),\n",
    "        \n",
    "        ('KNeighborsClassifier', KNeighborsClassifier(), {\n",
    "            'model__metric': [dfHp.KNN__metric[CounterHp]],\n",
    "            'model__n_neighbors': [dfHp.KNN__n_neighbors[CounterHp]],\n",
    "            'model__weights': [dfHp.KNN__weights[CounterHp]]\n",
    "        }),\n",
    "        \n",
    "        ('SVM', SVC(), {\n",
    "            'model__C': [dfHp.SVM__C[CounterHp]], \n",
    "            'model__gamma': [dfHp.SVM__gamma[CounterHp]], \n",
    "            'model__kernel': [dfHp.SVM__kernel[CounterHp]]\n",
    "            }),\n",
    "        \n",
    "        ('GradientBoosting', GradientBoostingClassifier(), {\n",
    "            'model__max_depth': [dfHp.GBC__max_depth[CounterHp]], \n",
    "            'model__min_samples_leaf': [dfHp.GBC__min_samples_leaf[CounterHp]], \n",
    "            'model__min_samples_split': [dfHp.GBC__min_samples_split[CounterHp]]\n",
    "            }),\n",
    "    ]\n",
    "\n",
    "    # Print scenario name\n",
    "    print(Scenario)\n",
    "    print (80 * '=')\n",
    "        \n",
    "    # Iteration over machine learning models\n",
    "    for model_name, model, param_grid in models:\n",
    "        \n",
    "        # Check if result file exists then take next model\n",
    "        if SubOperationSystem.checkIfFileExists(PathResult + Scenario + '_' + model_name + FileExtension + '.csv', False):\n",
    "            continue\n",
    "\n",
    "        # Print informations\n",
    "        print(f\"Training for {model_name} ...\")\n",
    "        print (60 * '=')\n",
    "\n",
    "        # With or without pca\n",
    "        if PCA:\n",
    "        \n",
    "            # Creata a pipeline with scaler, pca and model\n",
    "            pipeline = Pipeline([\n",
    "                ('scaler', StandardScaler()),\n",
    "                ('pca', PCA(n_components = n_components)),\n",
    "                ('model', model)\n",
    "            ])\n",
    "        \n",
    "        # Without PCA\n",
    "        else:\n",
    "        \n",
    "            # Creata a pipeline with scaler, pca and model\n",
    "            pipeline = Pipeline([\n",
    "                ('scaler', StandardScaler()),\n",
    "                ('model', model)\n",
    "            ])\n",
    "        \n",
    "\n",
    "        # Train the model (with pipeline)\n",
    "        pipeline.fit(X_train, y_train)\n",
    "\n",
    "        # Prediction\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "\n",
    "        # Create classification for accuracy for each label\n",
    "        reportLabel = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "        # Extract accuracy for each label\n",
    "        accuracy_per_class = {str(int(cls)): metrics['precision'] for cls, metrics in reportLabel.items() if cls.isdigit()}\n",
    "\n",
    "        # Print accuracy_per_class\n",
    "        print (\"accuracy_per_class\", accuracy_per_class)\n",
    "\n",
    "        # Print line\n",
    "        print(60 * '-')\n",
    "\n",
    "        # Convert report to pandas format and save accuracy acc file\n",
    "        acc_report = pd.DataFrame([accuracy_per_class]).transpose()\n",
    "        acc_report.to_csv(PathResult + Scenario + '_' + model_name + FileExtension + '.acc', index=True)\n",
    "\n",
    "        # Create report for classifikation\n",
    "        reportClassification = classification_report(y_test, y_pred)\n",
    "\n",
    "        # Create Report F1-Score\n",
    "        reportF1Score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        # Print reports\n",
    "        print(f'\\nClassification Report:\\n{reportClassification}')\n",
    "        print(f'\\nF1-Score: {reportF1Score}')\n",
    "        print(60 * '-')\n",
    "\n",
    "        # Create confusion matrix\n",
    "        mcm = metrics.confusion_matrix(y_test, y_pred, normalize='all')\n",
    "\n",
    "        # Convert report to pandas format and save confusionmatrix\n",
    "        cm_report = pd.DataFrame(mcm).transpose()\n",
    "        cm_report.to_csv(PathResult + Scenario + '_' + model_name + FileExtension + '.cm', index=True)\n",
    "\n",
    "        # Plot confusion matrix\n",
    "        sns.heatmap(pd.DataFrame(mcm), annot=True, cmap=\"YlGnBu\")\n",
    "        plt.title('Konfusionsmatrix - ' + str(Scenario) + ' - ' + str(model_name) + ' - PCA' , y=1.1)\n",
    "        plt.ylabel('Prognostizierte Klasse')\n",
    "        plt.xlabel('Tatsächliche Klasse')\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Save confusion matrix\n",
    "        plt.savefig(PathResult + Scenario + '_' + model_name + FileExtension + '_cm.png', pad_inches=5)\n",
    "\n",
    "        # Show confusion matrix\n",
    "        plt.show()\n",
    "\n",
    "        print (80 * '=')\n",
    "        print()\n",
    "\n",
    "        # Convert report to pandas format\n",
    "        clsfs_report = pd.DataFrame(classification_report(y_true = y_test, y_pred = y_pred, output_dict=True)).transpose()\n",
    "\n",
    "        # Save report to file\n",
    "        clsfs_report.to_csv(PathResult + Scenario + '_' + model_name + FileExtension + '.csv', index=True)\n",
    "    \n",
    "    # Increase counter for hyperparameter row\n",
    "    CounterHp += CounterHp\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
